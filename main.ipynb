{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -i IMAGE\n",
      "ipykernel_launcher.py: error: the following arguments are required: -i/--image\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "\thelp=\"path to the image file\")\n",
    "args = vars(ap.parse_args())\n",
    " \n",
    "# load the image from disk and display the width, height,\n",
    "# and depth\n",
    "image = cv2.imread(args[\"image\"])\n",
    "(h, w, d) = image.shape\n",
    "print(\"w: {}, h: {}, d: {}\".format(w, h, d))\n",
    " \n",
    "# show the image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# list all files of the input folder\n",
    "folder_name = \"input_test\"\n",
    "img_ar = [folder_name+\"/\"+s for s in os.listdir(folder_name)]\n",
    "output_folder = \"output_test\"\n",
    "\n",
    "# font for the text written on image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# These file contains trained classifiers for detecting human face and cat face\n",
    "human_cas_file = \"human.xml\"\n",
    "cat_cas_file = \"cat.xml\"\n",
    "\n",
    "# Loading the classifier of faces of human and cat\n",
    "human_cas = cv2.CascadeClassifier(human_cas_file)\n",
    "cat_cas = cv2.CascadeClassifier(cat_cas_file)\n",
    "\n",
    "# Looping through each image of image list\n",
    "for img_file in img_ar:\n",
    "    # splits image's file name only and use it as the output image's name\n",
    "    img_file_only_name = img_file.split(\"/\")[1]\n",
    "    # reading the image\n",
    "    img = cv2.imread(img_file)\n",
    "\n",
    "    # resizing the image keeping the original aspect ratio\n",
    "    weight, height, channel = img.shape\n",
    "    new_weight = 500\n",
    "    aspect_ratio = (new_weight*1.0) / height\n",
    "    new_height = int(weight*aspect_ratio)\n",
    "    resize = (new_weight,new_height)\n",
    "    img = cv2.resize(img, resize, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # converts to gray scale image\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detection of cat face\n",
    "    cat_face_ar = cat_cas.detectMultiScale(\n",
    "        img_gray,\n",
    "        scaleFactor = 1.15,\n",
    "        minNeighbors = 4,\n",
    "        minSize = (50,50)\n",
    "        )\n",
    "\n",
    "    # detection of human face\n",
    "    human_face_ar = human_cas.detectMultiScale(\n",
    "        img_gray,\n",
    "        scaleFactor = 1.15,\n",
    "        minNeighbors = 7,\n",
    "        minSize = (80,80)\n",
    "        )\n",
    "\n",
    "    # marking cat faces\n",
    "    for(x,y,w,h) in cat_face_ar:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.putText(img,\"Cat\",(x,y-10),font,0.55,(0,255,0),1)\n",
    "\n",
    "    # marking human faces\n",
    "    for(x,y,w,h) in human_face_ar:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        cv2.putText(img,\"Human\",(x,y-10),font,0.55,(0,0,255),1)\n",
    "\n",
    "    # saves and shows the detected and marked images\n",
    "    output_file = output_folder+\"/out_\"+img_file_only_name\n",
    "    # Comment the below line if you do not want to show marked image on screen\n",
    "    cv2.imshow(output_file, img)\n",
    "    cv2.imwrite(output_file,img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print(\"The processing of the images has been completed.\")\n",
    "print(\"Check \"+output_folder+\" folder to see the result.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
